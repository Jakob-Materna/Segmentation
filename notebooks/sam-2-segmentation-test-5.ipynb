{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5247b61c-e7cc-4850-b292-00c56b879698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "502c79f0-8e23-4fb1-8447-fdce13656588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# select the device for computation\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    # use bfloat16 for the entire notebook\n",
    "    torch.autocast(\"cuda\", dtype=torch.bfloat16).__enter__()\n",
    "    # turn on tfloat32 for Ampere GPUs (https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices)\n",
    "    if torch.cuda.get_device_properties(0).major >= 8:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "elif device.type == \"mps\":\n",
    "    print(\n",
    "        \"\\nSupport for MPS devices is preliminary. SAM 2 is trained with CUDA and might \"\n",
    "        \"give numerically different outputs and sometimes degraded performance on MPS. \"\n",
    "        \"See e.g. https://github.com/pytorch/pytorch/issues/84936 for a discussion.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "184c8d31-0ff5-475d-a657-7d89f21a37c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_anns(anns, borders=True):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
    "    img[:, :, 3] = 0\n",
    "    for ann in sorted_anns:\n",
    "        m = ann['segmentation']\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.5]])\n",
    "        img[m] = color_mask \n",
    "        if borders:\n",
    "            import cv2\n",
    "            contours, _ = cv2.findContours(m.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) \n",
    "            # Try to smooth contours\n",
    "            contours = [cv2.approxPolyDP(contour, epsilon=0.01, closed=True) for contour in contours]\n",
    "            cv2.drawContours(img, contours, -1, (0, 0, 1, 0.4), thickness=1) \n",
    "\n",
    "    ax.imshow(img)\n",
    "\n",
    "def show_mask(mask, ax, random_color=False, borders = True):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask = mask.astype(np.uint8)\n",
    "    mask_image =  mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    if borders:\n",
    "        import cv2\n",
    "        contours, _ = cv2.findContours(mask,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) \n",
    "        # Try to smooth contours\n",
    "        contours = [cv2.approxPolyDP(contour, epsilon=0.01, closed=True) for contour in contours]\n",
    "        mask_image = cv2.drawContours(mask_image, contours, -1, (1, 1, 1, 0.5), thickness=2) \n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='.', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='.', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "\n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0, 0, 0, 0), lw=2))    \n",
    "\n",
    "def show_masks(image, masks, scores, point_coords=None, box_coords=None, input_labels=None, borders=True):\n",
    "    for i, (mask, score) in enumerate(zip(masks, scores)):\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(image)\n",
    "        show_mask(mask, plt.gca(), borders=borders)\n",
    "        if point_coords is not None:\n",
    "            assert input_labels is not None\n",
    "            show_points(point_coords, input_labels, plt.gca())\n",
    "        if box_coords is not None:\n",
    "            # boxes\n",
    "            show_box(box_coords, plt.gca())\n",
    "        if len(scores) > 1:\n",
    "            plt.title(f\"Mask {i+1}, Score: {score:.3f}\", fontsize=18)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e89ec74e-61d7-4f65-8e65-2cdad4ac8e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wing_1 = Image.open('../testdata/set_1/043870_L_O.JPG')\n",
    "wing_2 = Image.open('../testdata/set_1/043870_R_O.JPG')\n",
    "wing_3 = Image.open('../testdata/set_1/043874_L_O.JPG')\n",
    "wing_4 = Image.open('../testdata/set_1/043874_R_O.JPG')\n",
    "wing_5 = Image.open('../testdata/set_1/043878_L_O.JPG')\n",
    "wing_6 = Image.open('../testdata/set_1/043878_R_O.JPG')\n",
    "wing_7 = Image.open('../testdata/set_1/043884_L_O.JPG')\n",
    "\n",
    "wing = wing_2\n",
    "wing = np.array(wing.convert(\"RGB\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2fe6cd7f-728e-4b02-a361-55c1b183b140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscale_percent = 0.30 \\nnew_width = int(wing.shape[1] * scale_percent)\\nnew_height = int(wing.shape[0] * scale_percent)\\nwing = cv2.resize(wing, (new_width, new_height))\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "scale_percent = 0.30 \n",
    "new_width = int(wing.shape[1] * scale_percent)\n",
    "new_height = int(wing.shape[0] * scale_percent)\n",
    "wing = cv2.resize(wing, (new_width, new_height))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6c0c8ff9-f367-4ead-9410-3d9fa5d0dede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "\n",
    "sam2_checkpoint = \"/home/wsl/bin/segment-anything-2/checkpoints/sam2_hiera_large.pt\"\n",
    "model_cfg = \"sam2_hiera_l.yaml\"\n",
    "\n",
    "sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=device)\n",
    "\n",
    "predictor = SAM2ImagePredictor(sam2_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cba792-d7d6-4f5b-a40f-8d769c8b6313",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.set_image(wing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06533819-e416-426c-b007-4dad31d098d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = wing.shape[1]\n",
    "height = wing.shape[0]\n",
    "\n",
    "input_point = np.array([[1/3 * width, 1/2 * height], [2/3 * width, 1/2 * height]])\n",
    "input_label = np.array([1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2b8175-5948-4f66-bd58-cc66d82bc131",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(wing)\n",
    "show_points(input_point, input_label, plt.gca())\n",
    "plt.axis('off')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0523440c-70b5-4cba-966d-6b2c78cc5578",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask, scores, logits = predictor.predict(\n",
    "    point_coords=input_point,\n",
    "    point_labels=input_label,\n",
    "    multimask_output=False,\n",
    ")\n",
    "sorted_ind = np.argsort(scores)[::-1]\n",
    "mask = mask[sorted_ind]\n",
    "scores = scores[sorted_ind]\n",
    "logits = logits[sorted_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0a5f91-6316-4ddf-a8ad-cf5e31da7902",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_masks(wing, mask, scores, point_coords=input_point, input_labels=input_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c6edb8-3318-4d77-ac21-7f3efe3f4d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask2 = mask.squeeze()  # Removes the extra dimension if it's size 1\n",
    "new_image = mask2[..., None] * wing  # Add an axis to the mask to match the image's shape\n",
    "new_image = new_image.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c53b02c-7e15-441b-9199-e55d5c6c3d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(new_image)\n",
    "plt.axis('off')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44731fa-fcb9-4f1d-aa15-278d65a55d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404ed6b5-e095-4eb3-b3ee-ad2a3830fb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "sam2_checkpoint = \"/home/wsl/bin/segment-anything-2/checkpoints/sam2_hiera_large.pt\"\n",
    "model_cfg = \"sam2_hiera_l.yaml\"\n",
    "\n",
    "sam2 = build_sam2(model_cfg, sam2_checkpoint, device=device, apply_postprocessing=False)\n",
    "\n",
    "mask_generator = SAM2AutomaticMaskGenerator(sam2)\n",
    "\n",
    "masks = mask_generator.generate(new_image)\n",
    "\n",
    "end = time.time()\n",
    "print(round(end - start, 2), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e069385d-0d0f-40d4-9301-658776b35a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(wing)\n",
    "show_anns(masks)\n",
    "plt.axis('off')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e2f6b7-b8b1-4719-8895-fab3d5125246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
